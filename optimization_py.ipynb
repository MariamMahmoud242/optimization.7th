{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, lr=0.01, epochs=10, optimizer='gd', batch_size=32):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.optimizer = optimizer\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        m, n = X.shape\n",
        "        self.w = np.zeros(n)\n",
        "        self.b = 0\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            if self.optimizer == 'gd':\n",
        "                self._update(X, y)\n",
        "            elif self.optimizer == 'sgd':\n",
        "                for i in range(m):\n",
        "                    self._update(X[i:i+1], y[i:i+1])\n",
        "            elif self.optimizer == 'mbgd':\n",
        "                for i in range(0, m, self.batch_size):\n",
        "                    self._update(X[i:i+self.batch_size], y[i:i+self.batch_size])\n",
        "\n",
        "            y_hat = self.predict_proba(X)\n",
        "            loss = -np.mean(y * np.log(y_hat + 1e-15) + (1 - y) * np.log(1 - y_hat + 1e-15))\n",
        "            print(f\"Epoch {epoch+1}: Loss = {loss:.4f}\")\n",
        "\n",
        "    def _update(self, X, y):\n",
        "        m = len(y)\n",
        "        y_hat = self.sigmoid(np.dot(X, self.w) + self.b)\n",
        "        dw = np.dot(X.T, (y_hat - y)) / m\n",
        "        db = np.sum(y_hat - y) / m\n",
        "        self.w -= self.lr * dw\n",
        "        self.b -= self.lr * db\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return self.sigmoid(np.dot(X, self.w) + self.b)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return (self.predict_proba(X) >= 0.5).astype(int)\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "optimizers = ['gd', 'sgd', 'mbgd']\n",
        "\n",
        "for opt in optimizers:\n",
        "    print(f\"\\n--- Optimizer: {opt.upper()} ---\")\n",
        "    model = LogisticRegression(lr=0.01, epochs=10, optimizer=opt, batch_size=32)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaKtABCo8Bka",
        "outputId": "e4e4931d-c1cf-42b8-f832-00cb75fa106c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Optimizer: GD ---\n",
            "Epoch 1: Loss = 0.6893\n",
            "Epoch 2: Loss = 0.6856\n",
            "Epoch 3: Loss = 0.6819\n",
            "Epoch 4: Loss = 0.6783\n",
            "Epoch 5: Loss = 0.6747\n",
            "Epoch 6: Loss = 0.6712\n",
            "Epoch 7: Loss = 0.6677\n",
            "Epoch 8: Loss = 0.6643\n",
            "Epoch 9: Loss = 0.6610\n",
            "Epoch 10: Loss = 0.6577\n",
            "Epoch 11: Loss = 0.6544\n",
            "Epoch 12: Loss = 0.6512\n",
            "Epoch 13: Loss = 0.6481\n",
            "Epoch 14: Loss = 0.6449\n",
            "Epoch 15: Loss = 0.6419\n",
            "Epoch 16: Loss = 0.6389\n",
            "Epoch 17: Loss = 0.6359\n",
            "Epoch 18: Loss = 0.6330\n",
            "Epoch 19: Loss = 0.6301\n",
            "Epoch 20: Loss = 0.6273\n",
            "Accuracy: 0.83\n",
            "Precision: 0.8969072164948454\n",
            "Recall: 0.7837837837837838\n",
            "F1 Score: 0.8365384615384616\n",
            "Confusion Matrix:\n",
            " [[79 10]\n",
            " [24 87]]\n",
            "\n",
            "--- Optimizer: SGD ---\n",
            "Epoch 1: Loss = 0.3386\n",
            "Epoch 2: Loss = 0.3249\n",
            "Epoch 3: Loss = 0.3219\n",
            "Epoch 4: Loss = 0.3210\n",
            "Epoch 5: Loss = 0.3207\n",
            "Epoch 6: Loss = 0.3206\n",
            "Epoch 7: Loss = 0.3206\n",
            "Epoch 8: Loss = 0.3206\n",
            "Epoch 9: Loss = 0.3206\n",
            "Epoch 10: Loss = 0.3206\n",
            "Epoch 11: Loss = 0.3206\n",
            "Epoch 12: Loss = 0.3206\n",
            "Epoch 13: Loss = 0.3206\n",
            "Epoch 14: Loss = 0.3206\n",
            "Epoch 15: Loss = 0.3206\n",
            "Epoch 16: Loss = 0.3206\n",
            "Epoch 17: Loss = 0.3206\n",
            "Epoch 18: Loss = 0.3206\n",
            "Epoch 19: Loss = 0.3206\n",
            "Epoch 20: Loss = 0.3206\n",
            "Accuracy: 0.83\n",
            "Precision: 0.8666666666666667\n",
            "Recall: 0.8198198198198198\n",
            "F1 Score: 0.8425925925925926\n",
            "Confusion Matrix:\n",
            " [[75 14]\n",
            " [20 91]]\n",
            "\n",
            "--- Optimizer: MBGD ---\n",
            "Epoch 1: Loss = 0.6136\n",
            "Epoch 2: Loss = 0.5586\n",
            "Epoch 3: Loss = 0.5190\n",
            "Epoch 4: Loss = 0.4894\n",
            "Epoch 5: Loss = 0.4666\n",
            "Epoch 6: Loss = 0.4484\n",
            "Epoch 7: Loss = 0.4337\n",
            "Epoch 8: Loss = 0.4215\n",
            "Epoch 9: Loss = 0.4113\n",
            "Epoch 10: Loss = 0.4026\n",
            "Epoch 11: Loss = 0.3951\n",
            "Epoch 12: Loss = 0.3886\n",
            "Epoch 13: Loss = 0.3830\n",
            "Epoch 14: Loss = 0.3780\n",
            "Epoch 15: Loss = 0.3735\n",
            "Epoch 16: Loss = 0.3696\n",
            "Epoch 17: Loss = 0.3661\n",
            "Epoch 18: Loss = 0.3629\n",
            "Epoch 19: Loss = 0.3600\n",
            "Epoch 20: Loss = 0.3574\n",
            "Accuracy: 0.825\n",
            "Precision: 0.8877551020408163\n",
            "Recall: 0.7837837837837838\n",
            "F1 Score: 0.8325358851674641\n",
            "Confusion Matrix:\n",
            " [[78 11]\n",
            " [24 87]]\n"
          ]
        }
      ]
    }
  ]
}